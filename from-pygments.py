#!/usr/bin/env python3
"""Generates languages, styles, etc. from pygments for use with
source-highlight.
"""
import os

from pygments import lexers
from pygments import styles


BASE_DIR = "share/py-source-highlight"


def token_to_rulename(token):
    return str(token)  # [6:].lower().replace(".", '_')


#
# Language translators
#


def regex_to_rule(pyregex, rulename):
    rule = rulename
    regex = pyregex
    if pyregex.endswith("\\n"):
        rule += " start"
        regex = regex[:-2]
    rule += ' = "' + regex + '"'
    return rule


def genlang(lexer):
    name = lexer.name.lower()
    lines = ["# autogenerated from pygments for " + name]
    for pyregex, token in lexer.tokens["root"]:
        rulename = token_to_rulename(token)
        lines.append(regex_to_rule(pyregex, rulename))
    lang = "\n".join(lines) + "\n"
    fname = os.path.join(BASE_DIR, lexer.name.lower() + ".lang")
    with open(fname, "w") as f:
        f.write(lang)
    return fname


def add_to_lang_map(lexer, base, lang_map):
    lang_map[lexer.name] = base
    lang_map[lexer.name.lower()] = base
    for alias in lexer.aliases:
        lang_map[alias] = base
        lang_map[alias.lower()] = base
    for filename in lexer.filenames:
        _, _, name = filename.rpartition(".")
        lang_map[name] = base
        lang_map[name.lower()] = base
    for filename in lexer.alias_filenames:
        _, _, name = filename.rpartition(".")
        lang_map[name] = base
        lang_map[name.lower()] = base


def write_lang_map(lang_map):
    print("Writing lang.map")
    lines = []
    for key, value in sorted(lang_map.items()):
        lines.append(key + " = " + value)
    s = "\n".join(lines) + "\n"
    fname = os.path.join(BASE_DIR, "lang.map")
    with open(fname, "w") as f:
        f.write(s)


def genlangs():
    lexer_names = ["diff"]
    lang_map = {}
    for lexer_name in lexer_names:
        print("Generating lexer " + lexer_name)
        lexer = lexers.get_lexer_by_name(lexer_name)
        fname = genlang(lexer)
        base = os.path.basename(fname)
        add_to_lang_map(lexer, base, lang_map)
    write_lang_map(lang_map)


def genstyle(style, style_name):
    lines = []
    for token, color in sorted(style.styles.items()):
        rulename = token_to_rulename(token)

    fname = style_name + ".style"
    return fname


#
# Style translators
#

LOGICAL_COLORS = {
    "black": (0, 0, 0),
    "red": (255, 0, 0),
    "darkred": (170, 0, 0),
    "brown": (170, 85, 0),
    "yellow": (255, 255, 0),
    "cyan": (0, 255, 255),
    "blue": (0, 0, 255),
    "pink": (255, 0, 255),
    "purple": (170, 0, 170),
    "orange": (252, 127, 0),
    "brightorange": (252, 170, 0),
    "green": (0, 255, 0),
    "brightgreen": (85, 255, 85),
    "darkgreen": (0, 128, 0),
    "teal": (0, 128, 128),
    "gray": (170, 170, 170),
    "darkblue": (0, 0, 170),
    "white": (255, 255, 255),
}


def genstyles():
    style_names = ["monokai"]
    for style_name in style_names:
        print("Generating style " + style_name)
        style = styles.get_style_by_name(style_name)
        fname = genstyle(style, style_name)


#
# Main
#


def main(args=None):
    genlangs()
    genstyles()


if __name__ == "__main__":
    main()
